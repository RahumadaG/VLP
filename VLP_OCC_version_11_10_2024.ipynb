{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTrS1t-RwfZi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import recall_score\n",
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_PeB1F3iUWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce78714b-4e83-4859-a461-49c37a6548a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhWz1obXhuRb"
      },
      "outputs": [],
      "source": [
        "ruta_mayor = \"/content/drive/MyDrive/Colab Notebooks/IS_based_VLP_Dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dfDAwQyvoLu"
      },
      "outputs": [],
      "source": [
        "ruta_sigle_led = \"/VLP_Single_LED/VLP_Single_LED\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRc3Pjdzv3u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f617994f-8536-49b9-b8dd-f82b88cca0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/IS_based_VLP_Dataset/VLP_Single_LED/VLP_Single_LED\n"
          ]
        }
      ],
      "source": [
        "total_ruta_single_led = ruta_mayor + ruta_sigle_led\n",
        "print(total_ruta_single_led)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Número de folds\n",
        "k_folds = 5\n",
        "\n",
        "# Paso 2: Crear el objeto StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=123)\n",
        "\n",
        "# Listas para almacenar las métricas\n",
        "test_accuracies = []\n",
        "test_gmeans = []\n",
        "time_ = []"
      ],
      "metadata": {
        "id": "_b9nChl9HGss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamaño del lote\n",
        "batch_size = 64\n",
        "\n",
        "# Número de épocas\n",
        "epochs = 30\n",
        "\n",
        "# Paso 1: Obtener las rutas de las imágenes y las etiquetas\n",
        "image_paths = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "2EllorL5HHTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener los nombres de las clases\n",
        "class_names = sorted(os.listdir(total_ruta_single_led))\n",
        "class_indices = dict((name, index) for index, name in enumerate(class_names))\n",
        "print(class_names)\n",
        "print(class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTDVknTbHcY2",
        "outputId": "1e551e0d-9689-4ab5-c0ac-22ad6453d836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LED11', 'LED12', 'LED13', 'LED14', 'LED3', 'LED4', 'LED7', 'LED8']\n",
            "{'LED11': 0, 'LED12': 1, 'LED13': 2, 'LED14': 3, 'LED3': 4, 'LED4': 5, 'LED7': 6, 'LED8': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(total_ruta_single_led, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for fname in os.listdir(class_dir):\n",
        "            if fname.lower().endswith(('.png', '.jpg', '.jpeg')):  # Filtrar solo imágenes\n",
        "                fpath = os.path.join(class_dir, fname)\n",
        "                image_paths.append(fpath)\n",
        "                labels.append(class_indices[class_name])\n",
        "\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.array(labels)\n",
        "num_classes = len(class_names)\n",
        "print(\"Total de imágenes:\", len(image_paths))\n",
        "print(\"Clases:\", class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZw-t-_iHsOd",
        "outputId": "dfa1fa47-2e05-4e26-b97c-72f994970846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imágenes: 2840\n",
            "Clases: ['LED11', 'LED12', 'LED13', 'LED14', 'LED3', 'LED4', 'LED7', 'LED8']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(path, label):\n",
        "    # Leer y decodificar la imagen\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_image(image, channels=3)\n",
        "    image.set_shape([None, None, 3])\n",
        "    # Redimensionar la imagen\n",
        "    image = tf.image.resize(image, [150, 150])\n",
        "    # Aplicar normalización Min-Max\n",
        "    image = image / tf.math.reduce_max(tf.reshape(image, [-1, image.shape[-1]]), axis=0)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "rwsUGmUHKCTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el callback para G-mean\n",
        "class GMeanCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data):\n",
        "        super(GMeanCallback, self).__init__()\n",
        "        self.validation_data = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_true = []\n",
        "        y_pred_classes = []\n",
        "\n",
        "        for X_val_batch, y_val_batch in self.validation_data:\n",
        "            y_pred_batch = self.model.predict(X_val_batch)\n",
        "            y_pred_classes_batch = np.argmax(y_pred_batch, axis=1)\n",
        "\n",
        "            y_true.extend(y_val_batch.numpy())\n",
        "            y_pred_classes.extend(y_pred_classes_batch)\n",
        "\n",
        "        y_true = np.array(y_true)\n",
        "        y_pred_classes = np.array(y_pred_classes)\n",
        "\n",
        "        recalls = recall_score(y_true, y_pred_classes, average=None)\n",
        "        gmean = np.prod(recalls) ** (1.0 / len(recalls))\n",
        "\n",
        "        logs['val_gmean'] = gmean\n",
        "        print(f\" - val_gmean: {gmean:.4f}\")"
      ],
      "metadata": {
        "id": "DJbQZQL-pkCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_class_distribution(labels, dataset_name):\n",
        "    unique, counts = np.unique(labels, return_counts=True)\n",
        "    distribution = dict(zip(unique, counts))\n",
        "    print(f\"Distribución de clases en {dataset_name}: {distribution}\")"
      ],
      "metadata": {
        "id": "l7oKf7svuGJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Obtener las rutas de las imágenes y las etiquetas\n",
        "image_paths = []\n",
        "labels_list = []\n",
        "\n",
        "# Obtener los nombres de las clases\n",
        "class_names = sorted(os.listdir(total_ruta_single_led))\n",
        "class_indices = dict((name, index) for index, name in enumerate(class_names))\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(total_ruta_single_led, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for fname in os.listdir(class_dir):\n",
        "            if fname.lower().endswith(('.png', '.jpg', '.jpeg')):  # Filtrar solo imágenes\n",
        "                fpath = os.path.join(class_dir, fname)\n",
        "                image_paths.append(fpath)\n",
        "                labels_list.append(class_indices[class_name])\n",
        "\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.array(labels_list)  # labels es un array de NumPy\n",
        "num_classes = len(class_names)\n",
        "print(\"Total de imágenes:\", len(image_paths))\n",
        "print(\"Clases:\", class_names)\n",
        "print(f\"Tipo de labels: {type(labels)}\")  # Debería ser <class 'numpy.ndarray'>"
      ],
      "metadata": {
        "id": "yolqdByyHHrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0137c880-b6c5-4aa4-c3f3-93fcae738b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imágenes: 2840\n",
            "Clases: ['LED11', 'LED12', 'LED13', 'LED14', 'LED3', 'LED4', 'LED7', 'LED8']\n",
            "Tipo de labels: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(image_paths, labels), 1):\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"\\n----- Fold {fold} de {k_folds} -----\")\n",
        "    print(f\"Tipo de labels al inicio del fold {fold}: {type(labels)}\")  # Nueva línea\n",
        "\n",
        "    # Dividir las rutas y etiquetas en entrenamiento y prueba\n",
        "    X_train_paths, X_test_paths = image_paths[train_index], image_paths[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    # Paso 3: Dividir el conjunto de entrenamiento en entrenamiento y validación de manera estratificada\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=123)\n",
        "    for train_idx, val_idx in sss.split(X_train_paths, y_train):\n",
        "        X_train_fold, X_val_fold = X_train_paths[train_idx], X_train_paths[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # Reemplazar las variables con las nuevas divisiones\n",
        "    X_train_paths = X_train_fold\n",
        "    y_train = y_train_fold\n",
        "    X_val_paths = X_val_fold\n",
        "    y_val = y_val_fold\n",
        "\n",
        "    # Imprimir la distribución de clases\n",
        "    print_class_distribution(y_train, \"Entrenamiento\")\n",
        "    print_class_distribution(y_val, \"Validación\")\n",
        "    print_class_distribution(y_test, \"Prueba\")\n",
        "\n",
        "    # Paso 4: Crear datasets de TensorFlow a partir de las rutas y etiquetas\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    # Crear datasets sin sobrescribir labels_array\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((X_train_paths, y_train))\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices((X_val_paths, y_val))\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices((X_test_paths, y_test))\n",
        "\n",
        "    # Aplicar preprocesamiento y batching\n",
        "    train_ds = train_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    val_ds = val_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    test_ds = test_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    train_ds = train_ds.cache() \\\n",
        "                       .shuffle(buffer_size=1000) \\\n",
        "                       .batch(batch_size) \\\n",
        "                       .prefetch(buffer_size=AUTOTUNE)\n",
        "    val_ds = val_ds.cache() \\\n",
        "                   .batch(batch_size) \\\n",
        "                   .prefetch(buffer_size=AUTOTUNE)\n",
        "    test_ds = test_ds.batch(batch_size) \\\n",
        "                     .prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    # Paso 5: Definir y compilar el modelo\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "        tf.keras.layers.Dense(8, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics= ['accuracy'])\n",
        "\n",
        "    gmean_callback = GMeanCallback(validation_data=val_ds)\n",
        "\n",
        "    # Paso 6: Entrenar el modelo\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        callbacks=[gmean_callback],\n",
        "        verbose=1  # Puedes establecer verbose=0 para silenciar la salida\n",
        "    )\n",
        "\n",
        "    # Paso 7: Evaluar el modelo en el conjunto de prueba\n",
        "    test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\n",
        "    print(f\"Exactitud en prueba: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Calcular la G-mean en el conjunto de prueba\n",
        "    y_true = []\n",
        "    y_pred_classes = []\n",
        "\n",
        "    for images, labels1 in test_ds:\n",
        "        y_true.extend(labels1.numpy())\n",
        "        y_pred = model.predict(images)\n",
        "        y_pred_classes_batch = np.argmax(y_pred, axis=1)\n",
        "        y_pred_classes.extend(y_pred_classes_batch)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred_classes = np.array(y_pred_classes)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    recalls = recall_score(y_true, y_pred_classes, average=None)\n",
        "    gmean = np.prod(recalls) ** (1.0 / len(recalls))\n",
        "    print(f\"G-mean en prueba: {gmean:.4f}\")\n",
        "\n",
        "    # Almacenar las métricas\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    test_gmeans.append(gmean)\n",
        "    time_.append(end_time - start_time)\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "NHM3lq53IcM9",
        "outputId": "c20f0511-1ac3-45e7-ba8e-2a579647d64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor fold, (train_index, test_index) in enumerate(skf.split(image_paths, labels), 1):\\n\\n    start_time = time.time()\\n    print(f\"\\n----- Fold {fold} de {k_folds} -----\")\\n    print(f\"Tipo de labels al inicio del fold {fold}: {type(labels)}\")  # Nueva línea\\n\\n    # Dividir las rutas y etiquetas en entrenamiento y prueba\\n    X_train_paths, X_test_paths = image_paths[train_index], image_paths[test_index]\\n    y_train, y_test = labels[train_index], labels[test_index]\\n\\n    # Paso 3: Dividir el conjunto de entrenamiento en entrenamiento y validación de manera estratificada\\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=123)\\n    for train_idx, val_idx in sss.split(X_train_paths, y_train):\\n        X_train_fold, X_val_fold = X_train_paths[train_idx], X_train_paths[val_idx]\\n        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\\n\\n    # Reemplazar las variables con las nuevas divisiones\\n    X_train_paths = X_train_fold\\n    y_train = y_train_fold\\n    X_val_paths = X_val_fold\\n    y_val = y_val_fold\\n\\n    # Imprimir la distribución de clases\\n    print_class_distribution(y_train, \"Entrenamiento\")\\n    print_class_distribution(y_val, \"Validación\")\\n    print_class_distribution(y_test, \"Prueba\")\\n\\n    # Paso 4: Crear datasets de TensorFlow a partir de las rutas y etiquetas\\n    AUTOTUNE = tf.data.AUTOTUNE\\n\\n    # Crear datasets sin sobrescribir labels_array\\n    train_ds = tf.data.Dataset.from_tensor_slices((X_train_paths, y_train))\\n    val_ds = tf.data.Dataset.from_tensor_slices((X_val_paths, y_val))\\n    test_ds = tf.data.Dataset.from_tensor_slices((X_test_paths, y_test))\\n\\n    # Aplicar preprocesamiento y batching\\n    train_ds = train_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\\n    val_ds = val_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\\n    test_ds = test_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\\n\\n    train_ds = train_ds.cache()                        .shuffle(buffer_size=1000)                        .batch(batch_size)                        .prefetch(buffer_size=AUTOTUNE)\\n    val_ds = val_ds.cache()                    .batch(batch_size)                    .prefetch(buffer_size=AUTOTUNE)\\n    test_ds = test_ds.batch(batch_size)                      .prefetch(buffer_size=AUTOTUNE)\\n\\n    # Paso 5: Definir y compilar el modelo\\n\\n    model = tf.keras.Sequential([\\n        tf.keras.layers.Conv2D(32, (3, 3), activation=\\'relu\\', input_shape=(150, 150, 3)),\\n        tf.keras.layers.BatchNormalization(),\\n        tf.keras.layers.MaxPooling2D((2, 2)),\\n        tf.keras.layers.Dropout(0.25),\\n        tf.keras.layers.Flatten(),\\n        tf.keras.layers.Dense(256, activation=\\'relu\\'),\\n        tf.keras.layers.BatchNormalization(),\\n        tf.keras.layers.Dropout(0.5),\\n        tf.keras.layers.Dense(8, activation=\\'relu\\'),\\n        tf.keras.layers.Dense(8, activation=\\'softmax\\')\\n    ])\\n\\n    model.compile(optimizer=\\'adam\\',\\n              loss=\\'sparse_categorical_crossentropy\\',\\n              metrics= [\\'accuracy\\'])\\n\\n    gmean_callback = GMeanCallback(validation_data=val_ds)\\n\\n    # Paso 6: Entrenar el modelo\\n    history = model.fit(\\n        train_ds,\\n        validation_data=val_ds,\\n        epochs=epochs,\\n        callbacks=[gmean_callback],\\n        verbose=1  # Puedes establecer verbose=0 para silenciar la salida\\n    )\\n\\n    # Paso 7: Evaluar el modelo en el conjunto de prueba\\n    test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\\n    print(f\"Exactitud en prueba: {test_accuracy:.4f}\")\\n\\n    # Calcular la G-mean en el conjunto de prueba\\n    y_true = []\\n    y_pred_classes = []\\n\\n    for images, labels1 in test_ds:\\n        y_true.extend(labels1.numpy())\\n        y_pred = model.predict(images)\\n        y_pred_classes_batch = np.argmax(y_pred, axis=1)\\n        y_pred_classes.extend(y_pred_classes_batch)\\n\\n    y_true = np.array(y_true)\\n    y_pred_classes = np.array(y_pred_classes)\\n\\n    end_time = time.time()\\n\\n    recalls = recall_score(y_true, y_pred_classes, average=None)\\n    gmean = np.prod(recalls) ** (1.0 / len(recalls))\\n    print(f\"G-mean en prueba: {gmean:.4f}\")\\n\\n    # Almacenar las métricas\\n    test_accuracies.append(test_accuracy)\\n    test_gmeans.append(gmean)\\n    time_.append(end_time - start_time)\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "RZXMqVObSUeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean\n",
        "\"\"\"\n",
        "print(np.mean(test_accuracies))\n",
        "print(np.mean(test_gmeans))\n",
        "print(np.mean(time_))\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TZuvZjD4QQAz",
        "outputId": "898ee8bf-ba8d-4f72-b82e-75602c01ab1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(np.mean(test_accuracies))\\nprint(np.mean(test_gmeans))\\nprint(np.mean(time_))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sd\n",
        "\"\"\"\n",
        "print(np.std(test_accuracies))\n",
        "print(np.std(test_gmeans))\n",
        "print(np.std(time_))\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IKMGLb5QQu-l",
        "outputId": "557fa921-be7e-431b-bcf2-352675341129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(np.std(test_accuracies))\\nprint(np.std(test_gmeans))\\nprint(np.std(time_))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Número de folds\n",
        "k_folds = 5\n",
        "\n",
        "# Mezclar los datos antes del proceso de K-Fold\n",
        "image_paths, labels = shuffle(image_paths, labels, random_state=123)\n",
        "\n",
        "# Paso 2: Crear el objeto StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=123)\n",
        "\n",
        "# Listas para almacenar las métricas\n",
        "test_accuracies = []\n",
        "test_gmeans = []\n",
        "time_ = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(image_paths, labels), 1):\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"\\n----- Fold {fold} de {k_folds} -----\")\n",
        "    print(f\"Tipo de labels al inicio del fold {fold}: {type(labels)}\")  # Nueva línea\n",
        "\n",
        "    # Dividir las rutas y etiquetas en entrenamiento y prueba\n",
        "    X_train_paths, X_test_paths = image_paths[train_index], image_paths[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    # Imprimir la distribución de clases\n",
        "    print_class_distribution(y_train, \"Entrenamiento\")\n",
        "    print_class_distribution(y_test, \"Test\")\n",
        "\n",
        "    # Paso 4: Crear datasets de TensorFlow a partir de las rutas y etiquetas\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    # Crear datasets sin sobrescribir labels_array\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((X_train_paths, y_train))\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices((X_test_paths, y_test))\n",
        "\n",
        "    # Aplicar preprocesamiento y batching\n",
        "    train_ds = train_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    test_ds = test_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    train_ds = train_ds.cache() \\\n",
        "                       .shuffle(buffer_size=1000) \\\n",
        "                       .batch(batch_size) \\\n",
        "                       .prefetch(buffer_size=AUTOTUNE)\n",
        "    test_ds = test_ds.batch(batch_size) \\\n",
        "                     .prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    # Paso 5: Definir y compilar el modelo\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "        tf.keras.layers.Dense(8, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Paso 6: Entrenar el modelo\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=epochs,\n",
        "        verbose=1  # Puedes establecer verbose=0 para silenciar la salida\n",
        "    )\n",
        "\n",
        "    # Paso 7: Evaluar el modelo en el conjunto de prueba\n",
        "    test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\n",
        "    print(f\"Exactitud en prueba: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Calcular la G-Mean en el conjunto de prueba\n",
        "    y_true = []\n",
        "    y_pred_classes = []\n",
        "\n",
        "    for images, labels1 in test_ds:\n",
        "        y_true.extend(labels1.numpy())\n",
        "        y_pred = model.predict(images)\n",
        "        y_pred_classes_batch = np.argmax(y_pred, axis=1)\n",
        "        y_pred_classes.extend(y_pred_classes_batch)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred_classes = np.array(y_pred_classes)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Guardar y_true y y_pred_classes en archivos de texto\n",
        "    np.savetxt(f'y_true_fold_{fold}.txt', y_true, fmt='%d')\n",
        "    np.savetxt(f'y_pred_classes_fold_{fold}.txt', y_pred_classes, fmt='%d')\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    L = cm.shape[0]  # Número de clases\n",
        "\n",
        "    beta_i = []\n",
        "\n",
        "    for i in range(L):\n",
        "        # Verdaderos positivos para la clase i\n",
        "        true_positives = cm[i, i]\n",
        "        # Total de muestras reales de la clase i\n",
        "        total_actual = np.sum(cm[i, :])\n",
        "        beta = true_positives / total_actual if total_actual > 0 else 0\n",
        "        beta_i.append(beta)\n",
        "\n",
        "    beta_i = np.array(beta_i)\n",
        "\n",
        "    # Calcular G-Mean\n",
        "    product_beta = np.prod(beta_i)\n",
        "    gmean = product_beta ** (1 / L)\n",
        "\n",
        "    print(f\"Exactitud por clase (beta_i): {beta_i}\")\n",
        "    print(f\"G-mean en prueba: {gmean:.4f}\")\n",
        "\n",
        "    # Almacenar las métricas\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    test_gmeans.append(gmean)\n",
        "    time_.append(end_time - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5_NNTeEWYmK",
        "outputId": "347cc540-2931-4f3c-f6b0-c37ce52ef89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- Fold 1 de 5 -----\n",
            "Tipo de labels al inicio del fold 1: <class 'numpy.ndarray'>\n",
            "Distribución de clases en Entrenamiento: {0: 285, 1: 284, 2: 283, 3: 281, 4: 286, 5: 285, 6: 283, 7: 285}\n",
            "Distribución de clases en Test: {0: 71, 1: 71, 2: 70, 3: 71, 4: 72, 5: 71, 6: 71, 7: 71}\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 17s 390ms/step - loss: 0.7971 - accuracy: 0.6536\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 14s 384ms/step - loss: 0.3488 - accuracy: 0.8138\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.1293 - accuracy: 0.9934\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0459 - accuracy: 0.9974\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 14s 390ms/step - loss: 0.0263 - accuracy: 0.9978\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0190 - accuracy: 0.9974\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0135 - accuracy: 0.9982\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0123 - accuracy: 0.9982\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 14s 387ms/step - loss: 0.0106 - accuracy: 0.9978\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0088 - accuracy: 0.9982\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0082 - accuracy: 0.9982\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 14s 387ms/step - loss: 0.0077 - accuracy: 0.9982\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0077 - accuracy: 0.9982\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.0084 - accuracy: 0.9978\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0083 - accuracy: 0.9978\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0070 - accuracy: 0.9982\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 14s 390ms/step - loss: 0.0063 - accuracy: 0.9982\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 14s 396ms/step - loss: 0.0059 - accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 14s 390ms/step - loss: 0.0052 - accuracy: 0.9982\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0062 - accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0052 - accuracy: 0.9991\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0042 - accuracy: 0.9991\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0038 - accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 14s 395ms/step - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.0032 - accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0030 - accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.0029 - accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0034 - accuracy: 0.9987\n",
            "Exactitud en prueba: 0.9947\n",
            "2/2 [==============================] - 0s 48ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 48ms/step\n",
            "2/2 [==============================] - 0s 48ms/step\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "2/2 [==============================] - 0s 45ms/step\n",
            "2/2 [==============================] - 0s 50ms/step\n",
            "2/2 [==============================] - 0s 41ms/step\n",
            "Exactitud por clase (beta_i): [1.         1.         1.         0.98591549 0.98611111 1.\n",
            " 1.         0.98591549]\n",
            "G-mean en prueba: 0.9947\n",
            "\n",
            "----- Fold 2 de 5 -----\n",
            "Tipo de labels al inicio del fold 2: <class 'numpy.ndarray'>\n",
            "Distribución de clases en Entrenamiento: {0: 285, 1: 284, 2: 283, 3: 281, 4: 286, 5: 285, 6: 283, 7: 285}\n",
            "Distribución de clases en Test: {0: 71, 1: 71, 2: 70, 3: 71, 4: 72, 5: 71, 6: 71, 7: 71}\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 17s 393ms/step - loss: 0.5509 - accuracy: 0.8666\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.1257 - accuracy: 0.9811\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 14s 387ms/step - loss: 0.0520 - accuracy: 0.9930\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0310 - accuracy: 0.9952\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0216 - accuracy: 0.9956\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0175 - accuracy: 0.9956\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 14s 387ms/step - loss: 0.0155 - accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0121 - accuracy: 0.9965\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0108 - accuracy: 0.9974\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0095 - accuracy: 0.9974\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0091 - accuracy: 0.9969\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 14s 385ms/step - loss: 0.0082 - accuracy: 0.9965\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0076 - accuracy: 0.9965\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0069 - accuracy: 0.9974\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 14s 382ms/step - loss: 0.0064 - accuracy: 0.9982\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 14s 385ms/step - loss: 0.0057 - accuracy: 0.9982\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0052 - accuracy: 0.9982\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0055 - accuracy: 0.9982\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0048 - accuracy: 0.9982\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 14s 394ms/step - loss: 0.0047 - accuracy: 0.9982\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0045 - accuracy: 0.9982\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 14s 380ms/step - loss: 0.0051 - accuracy: 0.9978\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 14s 387ms/step - loss: 0.0057 - accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0036 - accuracy: 0.9982\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0036 - accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 14s 387ms/step - loss: 0.0046 - accuracy: 0.9982\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 14s 382ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0033 - accuracy: 0.9982\n",
            "Exactitud en prueba: 1.0000\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "2/2 [==============================] - 0s 45ms/step\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "2/2 [==============================] - 0s 45ms/step\n",
            "2/2 [==============================] - 0s 45ms/step\n",
            "2/2 [==============================] - 0s 45ms/step\n",
            "2/2 [==============================] - 0s 44ms/step\n",
            "2/2 [==============================] - 0s 44ms/step\n",
            "2/2 [==============================] - 0s 36ms/step\n",
            "Exactitud por clase (beta_i): [1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "G-mean en prueba: 1.0000\n",
            "\n",
            "----- Fold 3 de 5 -----\n",
            "Tipo de labels al inicio del fold 3: <class 'numpy.ndarray'>\n",
            "Distribución de clases en Entrenamiento: {0: 285, 1: 284, 2: 282, 3: 282, 4: 286, 5: 284, 6: 284, 7: 285}\n",
            "Distribución de clases en Test: {0: 71, 1: 71, 2: 71, 3: 70, 4: 72, 5: 72, 6: 70, 7: 71}\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 17s 398ms/step - loss: 0.5955 - accuracy: 0.8006\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.1250 - accuracy: 0.9811\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0387 - accuracy: 0.9947\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0217 - accuracy: 0.9965\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 14s 398ms/step - loss: 0.0141 - accuracy: 0.9978\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0113 - accuracy: 0.9978\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 14s 400ms/step - loss: 0.0090 - accuracy: 0.9982\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0074 - accuracy: 0.9978\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0061 - accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0051 - accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0054 - accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 14s 387ms/step - loss: 0.0038 - accuracy: 0.9991\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 14s 385ms/step - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0035 - accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 14s 384ms/step - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0037 - accuracy: 0.9987\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.0040 - accuracy: 0.9987\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 14s 390ms/step - loss: 0.0031 - accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0029 - accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 14s 394ms/step - loss: 0.0040 - accuracy: 0.9987\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0035 - accuracy: 0.9982\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0038 - accuracy: 0.9982\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 14s 395ms/step - loss: 0.0040 - accuracy: 0.9982\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 14s 385ms/step - loss: 0.0036 - accuracy: 0.9982\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0034 - accuracy: 0.9987\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 14s 390ms/step - loss: 0.0038 - accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0023 - accuracy: 0.9996\n",
            "Exactitud en prueba: 0.9982\n",
            "2/2 [==============================] - 0s 48ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 48ms/step\n",
            "2/2 [==============================] - 0s 50ms/step\n",
            "2/2 [==============================] - 0s 50ms/step\n",
            "2/2 [==============================] - 0s 53ms/step\n",
            "2/2 [==============================] - 0s 53ms/step\n",
            "2/2 [==============================] - 0s 50ms/step\n",
            "2/2 [==============================] - 0s 38ms/step\n",
            "Exactitud por clase (beta_i): [1.         1.         1.         1.         1.         1.\n",
            " 1.         0.98591549]\n",
            "G-mean en prueba: 0.9982\n",
            "\n",
            "----- Fold 4 de 5 -----\n",
            "Tipo de labels al inicio del fold 4: <class 'numpy.ndarray'>\n",
            "Distribución de clases en Entrenamiento: {0: 285, 1: 284, 2: 282, 3: 282, 4: 287, 5: 285, 6: 283, 7: 284}\n",
            "Distribución de clases en Test: {0: 71, 1: 71, 2: 71, 3: 70, 4: 71, 5: 71, 6: 71, 7: 72}\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 17s 384ms/step - loss: 0.9627 - accuracy: 0.6118\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 14s 382ms/step - loss: 0.4354 - accuracy: 0.8398\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.2357 - accuracy: 0.8680\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 14s 377ms/step - loss: 0.1132 - accuracy: 0.9754\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0404 - accuracy: 0.9974\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0202 - accuracy: 0.9974\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.0141 - accuracy: 0.9974\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0156 - accuracy: 0.9974\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0116 - accuracy: 0.9974\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 14s 387ms/step - loss: 0.0101 - accuracy: 0.9974\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 14s 387ms/step - loss: 0.0081 - accuracy: 0.9982\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.0071 - accuracy: 0.9982\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0063 - accuracy: 0.9982\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 14s 396ms/step - loss: 0.0058 - accuracy: 0.9982\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 14s 390ms/step - loss: 0.0048 - accuracy: 0.9987\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0050 - accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0054 - accuracy: 0.9991\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0050 - accuracy: 0.9982\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0047 - accuracy: 0.9987\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0050 - accuracy: 0.9991\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0043 - accuracy: 0.9991\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.0048 - accuracy: 0.9987\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 14s 390ms/step - loss: 0.0033 - accuracy: 0.9991\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 14s 396ms/step - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 14s 401ms/step - loss: 0.0025 - accuracy: 0.9991\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0030 - accuracy: 0.9991\n",
            "Exactitud en prueba: 0.9947\n",
            "2/2 [==============================] - 0s 48ms/step\n",
            "2/2 [==============================] - 0s 52ms/step\n",
            "2/2 [==============================] - 0s 48ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "Exactitud por clase (beta_i): [0.98591549 1.         1.         1.         0.98591549 0.98591549\n",
            " 1.         1.        ]\n",
            "G-mean en prueba: 0.9947\n",
            "\n",
            "----- Fold 5 de 5 -----\n",
            "Tipo de labels al inicio del fold 5: <class 'numpy.ndarray'>\n",
            "Distribución de clases en Entrenamiento: {0: 284, 1: 284, 2: 282, 3: 282, 4: 287, 5: 285, 6: 283, 7: 285}\n",
            "Distribución de clases en Test: {0: 72, 1: 71, 2: 71, 3: 70, 4: 71, 5: 71, 6: 71, 7: 71}\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 17s 392ms/step - loss: 0.8536 - accuracy: 0.7108\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.3281 - accuracy: 0.8930\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.2441 - accuracy: 0.8873\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 14s 385ms/step - loss: 0.1837 - accuracy: 0.8772\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.1033 - accuracy: 0.9551\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 14s 390ms/step - loss: 0.0351 - accuracy: 0.9982\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 14s 384ms/step - loss: 0.0174 - accuracy: 0.9982\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0125 - accuracy: 0.9982\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 14s 380ms/step - loss: 0.0101 - accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 14s 391ms/step - loss: 0.0100 - accuracy: 0.9991\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 14s 383ms/step - loss: 0.0071 - accuracy: 0.9991\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 14s 386ms/step - loss: 0.0057 - accuracy: 0.9996\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 14s 390ms/step - loss: 0.0037 - accuracy: 0.9996\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 14s 398ms/step - loss: 0.0031 - accuracy: 0.9996\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 14s 397ms/step - loss: 0.0037 - accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0038 - accuracy: 0.9996\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 14s 394ms/step - loss: 0.0026 - accuracy: 0.9996\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0021 - accuracy: 0.9996\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 14s 389ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0019 - accuracy: 0.9996\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 14s 394ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 14s 392ms/step - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 14s 393ms/step - loss: 8.6508e-04 - accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 14s 394ms/step - loss: 0.0021 - accuracy: 0.9996\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 14s 388ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 14s 401ms/step - loss: 0.0019 - accuracy: 0.9991\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 14s 398ms/step - loss: 8.8064e-04 - accuracy: 1.0000\n",
            "Exactitud en prueba: 0.9930\n",
            "2/2 [==============================] - 0s 49ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 50ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "2/2 [==============================] - 0s 47ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "Exactitud por clase (beta_i): [1.         1.         0.98591549 0.97142857 1.         1.\n",
            " 1.         0.98591549]\n",
            "G-mean en prueba: 0.9929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "        tf.keras.layers.Dense(8, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yTJ5yEQ1X-76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = model.optimizer.learning_rate.numpy()\n",
        "print(\"Learning rate:\", learning_rate)"
      ],
      "metadata": {
        "id": "_W2dcJDlZJjZ",
        "outputId": "1972fef9-847e-40c0-98f8-7b4ded1d6139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ffAQIe1Yv2P",
        "outputId": "0b72fe6e-432d-4f66-8088-c6a0e8298d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 148, 148, 32)      128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 175232)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               44859648  \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44863824 (171.14 MB)\n",
            "Trainable params: 44863248 (171.14 MB)\n",
            "Non-trainable params: 576 (2.25 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean\n",
        "print(np.mean(test_accuracies))\n",
        "print(np.mean(test_gmeans))\n",
        "print(np.mean(time_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePsHmFcXXNc1",
        "outputId": "b6dc00e7-c4b8-4046-e09e-3e657a7a6d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9961267709732056\n",
            "0.9960997933679747\n",
            "428.2570034980774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# std\n",
        "print(np.std(test_accuracies))\n",
        "print(np.std(test_gmeans))\n",
        "print(np.std(time_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT8O-3DAXYOl",
        "outputId": "ec09d813-73dc-4f57-f31a-d0159bcbfff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0025874858976153436\n",
            "0.0026131875057960104\n",
            "1.5676273506567808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round((428.2570034980774), 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Uz3mNNH71a",
        "outputId": "dd2c85e2-c453-41ae-c09e-0a740d34b775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "428.257"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNE/cOilEjOlAiT/K9xTaZf"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}